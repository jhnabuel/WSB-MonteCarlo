{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNOUS-rI7YpA"
      },
      "source": [
        "# Monte Carlo Simulation for Popular r/wsb Stocks\n",
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjGv9TY37XcK"
      },
      "outputs": [],
      "source": [
        "import praw\n",
        "from collections import Counter\n",
        "import re\n",
        "import pandas as pd\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from dotenv import load_dotenv\n",
        "import requests\n",
        "from praw.models import MoreComments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow5T-0AUs-Aj"
      },
      "source": [
        "# Get Reddit API credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Szrb3Jsp8Dbg"
      },
      "outputs": [],
      "source": [
        "# Reddit app credentials\n",
        "load_dotenv()  \n",
        "client_id = os.getenv(\"id\")\n",
        "client_secret = os.getenv(\"secret\")\n",
        "user_agent = os.getenv(\"user_agent\")\n",
        "reddit = praw.Reddit(\n",
        "    client_id = client_id,\n",
        "    client_secret = client_secret,\n",
        "    user_agent = user_agent,\n",
        "    username=\"Hashi118\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuliwD5L8DTw"
      },
      "source": [
        "# Get top year 1000 posts from r/WallStreetBets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK7RFeQAtMgu",
        "outputId": "52c12c36-d16f-43a5-de27-8938f7558bf9"
      },
      "outputs": [],
      "source": [
        "# Fetch top 100 posts from r/wallstreetbets\n",
        "subreddit = reddit.subreddit('wallstreetbets')\n",
        "top_posts = subreddit.top(time_filter=\"year\", limit=1000)\n",
        "\n",
        "# Simple regex to identify stock tickers\n",
        "ticker_pattern = re.compile(r'\\b[A-Z]{2,5}\\b')\n",
        "blacklist = {\"YOLO\", \"THE\", \"AND\", \"ALL\", \"BUY\", \"SELL\", \"HOLD\", \"FOR\", \"IT\", \"US\", \"TLDR\", \"DD\", \"USD\", \"EU\", \"AI\", \"CEO\", \"WSB\", \"UAE\"}\n",
        "\n",
        "tickers = []\n",
        "# Collect tickers\n",
        "for post in top_posts:\n",
        "  combined_text = post.title\n",
        "  matches = ticker_pattern.findall(combined_text)\n",
        "  filtered = [m for m in matches if m not in blacklist]\n",
        "  tickers.extend(filtered)\n",
        "\n",
        "      # Count most discussed tickers\n",
        "ticker_counts = Counter(tickers)\n",
        "\n",
        "print(\"Top discussed tickers (year):\")\n",
        "for ticker, count in ticker_counts.most_common(15):\n",
        "    print(f\"{ticker}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch top 100 posts from r/wallstreetbets\n",
        "subreddit = reddit.subreddit('wallstreetbets')\n",
        "top_posts = subreddit.top(time_filter=\"year\", limit=1000)\n",
        "for post in top_posts:\n",
        "    print(f\"{post.title}\"  + f\" {post.link_flair_text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Define if post body contains meaningful text (not just image) ---\n",
        "def is_text_body(body):\n",
        "    return bool(body and len(body.strip()) > 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting top posts for Nvidia (November 1, 2024 - April 30, 2025)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching posts from r/wallstreetbets matching: NVDA OR Nvidia\n",
            "Collected 5692 total rows (posts + comments)\n",
            "Saved to /Users/johnabuel/Desktop/stock data/nvda_top_posts.csv\n"
          ]
        }
      ],
      "source": [
        "# --- Config ---\n",
        "start_date = datetime(2024, 11, 1)\n",
        "end_date = datetime(2025, 4, 30)\n",
        "accepted_flairs = {\"DD\", \"Discussion\", \"Catalyst\", \"News\", \"YOLO\", \"Gain\", \"Loss\", \"Technical Analysis\"}\n",
        "search_query = \"NVDA OR Nvidia\"\n",
        "limit = 5000\n",
        "\n",
        "# --- Fetch posts ---\n",
        "subreddit = reddit.subreddit('wallstreetbets')\n",
        "posts = []\n",
        "\n",
        "print(f\"Fetching posts from r/wallstreetbets matching: {search_query}\")\n",
        "results = subreddit.search(search_query, sort=\"top\", time_filter=\"year\", limit=limit)\n",
        "\n",
        "for post in results:\n",
        "    flair = post.link_flair_text or \"\"\n",
        "\n",
        "    # Filter by flair\n",
        "    if flair not in accepted_flairs:\n",
        "        continue\n",
        "\n",
        "    # Convert timestamp to datetime\n",
        "    post_datetime = datetime.fromtimestamp(post.created_utc)\n",
        "    if not (start_date <= post_datetime <= end_date):\n",
        "        continue\n",
        "\n",
        "    title = post.title\n",
        "    body = post.selftext\n",
        "    url = post.url\n",
        "\n",
        "    # Must mention MSTR or MicroStrategy and have meaningful text\n",
        "    if (\"NVDA \" in title.upper() or \"NVIDIA\" in title.upper() or \n",
        "        \"NVDA\" in body.upper() or \"NVIDIA\" in body.upper()) and is_text_body(body):\n",
        "        \n",
        "        # Add main post\n",
        "        posts.append([\n",
        "            title,\n",
        "            body,\n",
        "            post.score,\n",
        "            post_datetime.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            url,\n",
        "            flair,\n",
        "            \"Post\"  # Label to distinguish\n",
        "        ])\n",
        "\n",
        "        # --- Fetch top-level comments ---\n",
        "        post.comments.replace_more(limit=50)\n",
        "        for comment in post.comments:\n",
        "            if isinstance(comment, MoreComments):\n",
        "                continue\n",
        "            if comment.body.strip() and len(comment.body) >= 10:  # Meaningful text\n",
        "                comment_datetime = datetime.fromtimestamp(comment.created_utc)\n",
        "                if start_date <= comment_datetime <= end_date:\n",
        "                    posts.append([\n",
        "                        f\"[Comment on] {title}\",\n",
        "                        comment.body,\n",
        "                        comment.score,\n",
        "                        comment_datetime.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                        url,\n",
        "                        flair,\n",
        "                        \"Comment\"  # Distinguish from post\n",
        "                    ])\n",
        "\n",
        "print(f\"Collected {len(posts)} total rows (posts + comments)\")\n",
        "\n",
        "# --- Save to CSV ---\n",
        "folder_path = \"/Users/johnabuel/Desktop/stock data\"\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "file_path = os.path.join(folder_path, \"nvda_top_posts.csv\")\n",
        "\n",
        "with open(file_path, \"w\", newline='', encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Title\", \"Body\", \"Score\", \"Date\", \"URL\", \"Flair\", \"Type\"])\n",
        "    writer.writerows(posts)\n",
        "\n",
        "print(f\"Saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting top posts for MicroStrategy (November 1, 2024 - April 30, 2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching posts from r/wallstreetbets matching: MSTR OR Microstrategy\n",
            "Collected 8355 total rows (posts + comments)\n",
            "Saved to /Users/johnabuel/Desktop/stock data/mstr_top_posts.csv\n"
          ]
        }
      ],
      "source": [
        "# --- Config ---\n",
        "start_date = datetime(2024, 11, 1)\n",
        "end_date = datetime(2025, 4, 30)\n",
        "accepted_flairs = {\"DD\", \"Discussion\", \"Catalyst\", \"News\", \"YOLO\", \"Gain\", \"Loss\", \"Technical Analysis\"}\n",
        "search_query = \"MSTR OR Microstrategy\"\n",
        "limit = 5000\n",
        "\n",
        "# --- Fetch posts ---\n",
        "subreddit = reddit.subreddit('wallstreetbets')\n",
        "posts = []\n",
        "\n",
        "print(f\"Fetching posts from r/wallstreetbets matching: {search_query}\")\n",
        "results = subreddit.search(search_query, sort=\"top\", time_filter=\"year\", limit=limit)\n",
        "\n",
        "for post in results:\n",
        "    flair = post.link_flair_text or \"\"\n",
        "\n",
        "    # Filter by flair\n",
        "    if flair not in accepted_flairs:\n",
        "        continue\n",
        "\n",
        "    # Convert timestamp to datetime\n",
        "    post_datetime = datetime.fromtimestamp(post.created_utc)\n",
        "    if not (start_date <= post_datetime <= end_date):\n",
        "        continue\n",
        "\n",
        "    title = post.title\n",
        "    body = post.selftext\n",
        "    url = post.url\n",
        "\n",
        "    # Must mention MSTR or MicroStrategy and have meaningful text\n",
        "    if (\"MSTR\" in title.upper() or \"MICROSTRATEGY\" in title.upper() or \n",
        "        \"MSTR\" in body.upper() or \"MICROSTRATEGY\" in body.upper()) and is_text_body(body):\n",
        "        \n",
        "        # Add main post\n",
        "        posts.append([\n",
        "            title,\n",
        "            body,\n",
        "            post.score,\n",
        "            post_datetime.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            url,\n",
        "            flair,\n",
        "            \"Post\"  # Label to distinguish\n",
        "        ])\n",
        "\n",
        "        # --- Fetch top-level comments ---\n",
        "        post.comments.replace_more(limit=0)\n",
        "        for comment in post.comments:\n",
        "            if isinstance(comment, MoreComments):\n",
        "                continue\n",
        "            if comment.body.strip() and len(comment.body) >= 10:  # Meaningful text\n",
        "                comment_datetime = datetime.fromtimestamp(comment.created_utc)\n",
        "                if start_date <= comment_datetime <= end_date:\n",
        "                    posts.append([\n",
        "                        f\"[Comment on] {title}\",\n",
        "                        comment.body,\n",
        "                        comment.score,\n",
        "                        comment_datetime.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                        url,\n",
        "                        flair,\n",
        "                        \"Comment\"  # Distinguish from post\n",
        "                    ])\n",
        "\n",
        "print(f\"Collected {len(posts)} total rows (posts + comments)\")\n",
        "\n",
        "# --- Save to CSV ---\n",
        "folder_path = \"/Users/johnabuel/Desktop/stock data\"\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "file_path = os.path.join(folder_path, \"mstr_top_posts.csv\")\n",
        "\n",
        "with open(file_path, \"w\", newline='', encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Title\", \"Body\", \"Score\", \"Date\", \"URL\", \"Flair\", \"Type\"])\n",
        "    writer.writerows(posts)\n",
        "\n",
        "print(f\"Saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching 'top' and 'relevance' posts for: MSTR OR Microstrategy\n",
            "Fetching top posts...\n",
            "Fetching relevance posts...\n",
            "Collected 152 unique posts\n",
            "Saved to /Users/johnabuel/Desktop/stock data/mstr_top_relevant_posts.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Config ---\n",
        "start_date = datetime(2024, 11, 1)\n",
        "end_date = datetime(2025, 4, 30)\n",
        "accepted_flairs = {\"DD\", \"Discussion\", \"Catalyst\", \"News\", \"YOLO\", \"Gain\", \"Loss\", \"Technical Analysis\"}\n",
        "search_query = \"MSTR OR Microstrategy\"\n",
        "limit = 3000\n",
        "\n",
        "# --- Fetch posts ---\n",
        "subreddit = reddit.subreddit(\"wallstreetbets\")\n",
        "seen = set()  # To track duplicates\n",
        "posts = []\n",
        "\n",
        "print(f\"Fetching 'top' and 'relevance' posts for: {search_query}\")\n",
        "\n",
        "for sort_type in [\"top\", \"relevance\"]:\n",
        "    print(f\"Fetching {sort_type} posts...\")\n",
        "    results = subreddit.search(search_query, sort=sort_type, time_filter=\"year\", limit=limit)\n",
        "\n",
        "    for post in results:\n",
        "        flair = post.link_flair_text or \"\"\n",
        "        if flair not in accepted_flairs:\n",
        "            continue\n",
        "\n",
        "        post_datetime = datetime.fromtimestamp(post.created_utc)\n",
        "        if not (start_date <= post_datetime <= end_date):\n",
        "            continue\n",
        "\n",
        "        title = post.title.strip()\n",
        "        body = post.selftext.strip()\n",
        "        url = post.url\n",
        "        identifier = (title.lower(), body.lower(), post_datetime.strftime('%Y-%m-%d'))  # Unique ID\n",
        "\n",
        "        if identifier in seen:\n",
        "            continue  # Skip duplicates\n",
        "        seen.add(identifier)\n",
        "\n",
        "        if (\"MSTR\" in title.upper() or \"MICROSTRATEGY\" in title.upper() or \n",
        "            \"MSTR\" in body.upper() or \"MICROSTRATEGY\" in body.upper()) and body and len(body) >= 10:\n",
        "            \n",
        "            posts.append([\n",
        "                title,\n",
        "                body,\n",
        "                post.score,\n",
        "                post_datetime.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                url,\n",
        "                flair,\n",
        "                \"Post\"\n",
        "            ])\n",
        "\n",
        "print(f\"Collected {len(posts)} unique posts\")\n",
        "\n",
        "# --- Save to CSV ---\n",
        "folder_path = \"/Users/johnabuel/Desktop/stock data\"\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "file_path = os.path.join(folder_path, \"mstr_top_relevant_posts.csv\")\n",
        "\n",
        "with open(file_path, \"w\", newline='', encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Title\", \"Body\", \"Score\", \"Date\", \"URL\", \"Flair\", \"Type\"])\n",
        "    writer.writerows(posts)\n",
        "\n",
        "print(f\"Saved to {file_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
